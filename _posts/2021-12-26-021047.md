---
layout: post
title: Introduction to Pandas
---

Pandas is a data manipulation tool that allows Python developers to handle data in a quick, efficient and extensive way.

Think that line above was way too fancy? Me too. Let's say, for now, that Pandas is just a file manager on steroids. Its main functionality resides in the fact that huge csv, xlsx, JSON (...) files can be rapidly converted into easily manipulable data structures, such as dataframes (`pandas.core.frame.DataFrame`) or series (`pandas.core.series.Series`). These data structures have some similarities with matrices, so if you have ever played with these, you are well suited for this tutorial.

## 1. Reading files

As in any file management process, the first step is to read a file. With Pandas, this can even be done for remote files. In this example, we're going to use a remote data archive, provided by [this url](https://archive.ics.uci.edu/ml/machine-learning-databases/autos/imports-85.data).

```python
import pandas as pd

URL = "https://archive.ics.uci.edu/ml/machine-learning-databases/autos/imports-85.data"
df = pd.read_csv(URL, header=None)
```

Let me answer some questions that might have popped out while you were reading this piece of code:

* `read_csv` is the Pandas method used to read CSV (_Comma-Separated Values_) files. There are other methods such as `read_json` that are used in the same fashion to read other file formats. All the available methods can be found in the Pandas documentation. <!-- Add link here. -->


* `df` is the variable used to contain the data returned by the `read_csv` method. It is usually named `df` since that stands for _data frame_, which is the exact data type of the object that the reading methods return.


* `header` is a parameter for the reading method. It can be an integer or a sequence of them. Its function is to determine which row is the header one (the row that contains the fancy names of each column's data). In this case, since the data retrieved from the URL has got no header row, its argument is `None`.

That said, let's hop into the next lesson: exploring the dataframe.

## 2. Dataframe inspection

There are plenty of methods that can be used to retrieve information from the dataframe (which, believe me, is a powerful debugging tool). Some of them just print some data on the screen, while others can be used to modify the dataframe in various ways.

### 2.1. Dataframe information

First of all, the most informative method that you will find in Pandas is `info`. It retrieves all meaningful information about the dataframe and prints it.

```python
df.info()
```

```
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 205 entries, 0 to 204
Data columns (total 26 columns):
 #   Column  Non-Null Count  Dtype
---  ------  --------------  -----
 0   0       205 non-null    int64
 1   1       205 non-null    object
 2   2       205 non-null    object
 3   3       205 non-null    object
 4   4       205 non-null    object
 5   5       205 non-null    object
 6   6       205 non-null    object
 7   7       205 non-null    object
 8   8       205 non-null    object
 9   9       205 non-null    float64
 10  10      205 non-null    float64
 11  11      205 non-null    float64
 12  12      205 non-null    float64
 13  13      205 non-null    int64
 14  14      205 non-null    object
 15  15      205 non-null    object
 16  16      205 non-null    int64
 17  17      205 non-null    object
 18  18      205 non-null    object
 19  19      205 non-null    object
 20  20      205 non-null    float64
 21  21      205 non-null    object
 22  22      205 non-null    object
 23  23      205 non-null    int64
 24  24      205 non-null    int64
 25  25      205 non-null    object
dtypes: float64(5), int64(5), object(16)
memory usage: 41.8+ KB
```

Let's take a closer look at what this chunk of information actually means:

* `<class 'pandas.core.frame.DataFrame'>` represents the data structure of the variable `df`, which in this case is a Pandas `DataFrame`.


* `RangeIndex: 205 entries, 0 to 204` indicates how many rows are in the dataframe. It also provides with a reminder that indices <!-- Check spelling -->in Python start from `0`, so for a total amount of `205` entries (rows), the minimum and maximum indices <!-- Check spelling -->would be `0` and `204`, respectively.


* `Data columns (total 26 columns)` states that there is a grand total of 26 columns full of data.


* Right below the amount of columns is the information for each column in the dataframe. This represents the column index (`#`), the column name (`Column`), the amount of non-null elements in said column (`Non-Null Count`) and the data type of its elements (`Dtype`). Don't worry if you don't entirely understand these concepts. They will be explained in depth later on this introduction.


* `dtypes` offers information about the data types present in the dataframe. In this case there are five `float64` columns, five `int64` and 16 `object` ones. Again, these concepts will be explained later on.


* Last but not least, the `memory usage` represents how much RAM memory the dataframe is using on your device.


### 2.2. Dataframe visualization

Okay, so now we have some information about what the dataframe contains, but what if we actually want to _see_ what's inside? Say no more. There are three main ways you can display the dataframe. The first one is calling the good old `print` function with the whole dataframe:

```python
print(df)
```

This will get you a lot of information. Note that there are ellipsis (`...`) in some parts of the representation. They are used to represent the skipped rows and columns due to space limitations.

```
     0    1            2       3      4     5   ...    20   21    22  23  24     25
0     3    ?  alfa-romero     gas    std   two  ...   9.0  111  5000  21  27  13495
1     3    ?  alfa-romero     gas    std   two  ...   9.0  111  5000  21  27  16500
2     1    ?  alfa-romero     gas    std   two  ...   9.0  154  5000  19  26  16500
3     2  164         audi     gas    std  four  ...  10.0  102  5500  24  30  13950
4     2  164         audi     gas    std  four  ...   8.0  115  5500  18  22  17450
..   ..  ...          ...     ...    ...   ...  ...   ...  ...   ...  ..  ..    ...
200  -1   95        volvo     gas    std  four  ...   9.5  114  5400  23  28  16845
201  -1   95        volvo     gas  turbo  four  ...   8.7  160  5300  19  25  19045
202  -1   95        volvo     gas    std  four  ...   8.8  134  5500  18  23  21485
203  -1   95        volvo  diesel  turbo  four  ...  23.0  106  4800  26  27  22470
204  -1   95        volvo     gas  turbo  four  ...   9.5  114  5400  19  25  22625

[205 rows x 26 columns]
```

The other two are Pandas-specific methods, `head(n)` and `tail(n)`. You can imagine what they do just by looking at their names: the first one returns the `n` first rows, while the last one returns the last `n` rows. Note that I said _returns_ and not _displays_. This means that in order to represent that data, you've got to use the `print` function:

```python
print(df.head(5))
```

```
   0    1            2    3    4     5   ...    20   21    22  23  24     25
0   3    ?  alfa-romero  gas  std   two  ...   9.0  111  5000  21  27  13495
1   3    ?  alfa-romero  gas  std   two  ...   9.0  111  5000  21  27  16500
2   1    ?  alfa-romero  gas  std   two  ...   9.0  154  5000  19  26  16500
3   2  164         audi  gas  std  four  ...  10.0  102  5500  24  30  13950
4   2  164         audi  gas  std  four  ...   8.0  115  5500  18  22  17450

[5 rows x 26 columns]
```

```python
print(df.tail(5))
```

```
     0    1      2       3      4     5   ...    20   21    22  23  24     25
200  -1   95  volvo     gas    std  four  ...   9.5  114  5400  23  28  16845
201  -1   95  volvo     gas  turbo  four  ...   8.7  160  5300  19  25  19045
202  -1   95  volvo     gas    std  four  ...   8.8  134  5500  18  23  21485
203  -1   95  volvo  diesel  turbo  four  ...  23.0  106  4800  26  27  22470
204  -1   95  volvo     gas  turbo  four  ...   9.5  114  5400  19  25  22625

[5 rows x 26 columns]
```

### 2.3. Column/row information

A dataframe's columns can be visualized through the `columns` attribute. The returned value is an `Index` object or one of its variants (`Int64Index`, `Float64Index`...):

```python
print(df.columns)
```

```
Int64Index([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,
            17, 18, 19, 20, 21, 22, 23, 24, 25],
           dtype='int64')
```

In this case, since the columns haven't got a proper description, they are represented as a sequence of integer numbers of data type "_64-bit integer_", also known as `int64`.

The dataframe's rows can be visualized in a similar way, using the `index` attribute. The returned value is, again, an `Index` object variant: `RangeIndex`.

```python
print(df.index)
```

```
RangeIndex(start=0, stop=205, step=1)
```

Since there are 206 columns, the `RangeIndex` represents a numerical range between `0` and `205` with a step (increment) of `1`.

You might be wondering "okay, but what how is this useful in any way?". Well, this is especially useful since these attributes can be modified. For example, let's add a proper header row to the dataframe. This can be done by changing the `columns` attribute (do not mix up the terms "row" and "column". The `columns` attribute returns the header element for each column of the dataframe. The combination of the header elements of every column is the header row.).

```python
df.columns = [
    "symboling", "normalized-losses", "make", "fuel-type", "aspiration", "num-of-doors", "body-style",
    "drive-wheels", "engine-location", "wheel-base", "length","width", "height", "curb-weight", "engine-type",
    "num-of-cylinders", "engine-size", "fuel-system", "bore", "stroke", "compression-ratio", "horsepower",
    "peak-rpm", "city-mpg", "highway-mpg", "price"
]

print(df.head(5))
```

```
   symboling normalized-losses         make  ... city-mpg highway-mpg  price
0          3                 ?  alfa-romero  ...       21          27  13495
1          3                 ?  alfa-romero  ...       21          27  16500
2          1                 ?  alfa-romero  ...       19          26  16500
3          2               164         audi  ...       24          30  13950
4          2               164         audi  ...       18          22  17450

[5 rows x 26 columns]
```

As of now, the header of each column provides with way more information than it did before. You might have noticed that the amount of visible columns has been reduced. This is due to the fact that the new column headers are wider than the previous ones and therefore occupy more space.

### 2.3. Element access

So, we've learned how to display row and column identifiers, but what about the elements that they represent? Accessing a column should return all row values for that specific column, while accessing a row should return all column values for that specific row. Fortunately, Pandas has got us covered here:

Just like if you were accessing elements in a Python list (`list[0]` -> element 1, `list[1]` -> element 2...), columns can be retrieved in Pandas with a similar syntax:

```python
print(df["price"])
```

```
0      13495
1      16500
2      16500
3      13950
4      17450
       ...
200    16845
201    19045
202    21485
203    22470
204    22625
Name: price, Length: 205, dtype: object
```

As you can see, this returns all row elements in that given column, `"price"`. Note that columns are accessed using one of the identifiers provided in the `columns` attribute. If you ever forget whether or not a given identifier is represents a column, you can check it out using the following syntax:

```python
"price" in df.columns
```

If that evaluation returns `True`, then it is safe to use `df["price"]`. Else, an error will raise.

Furthermore, let's say that you wanted to select not only one column but a subset of columns (which would mean extracting a reduced matrix from the original one). You can do that using the following syntax: `<dataframe>[[<column_1>, <column_2>, ..., <column_n>]]`. Let's see an example:

```python
subset = df[["make", "price"]]

print(subset)
```

```
            make  price
0    alfa-romero  13495
1    alfa-romero  16500
2    alfa-romero  16500
3           audi  13950
4           audi  17450
..           ...    ...
200        volvo  16845
201        volvo  19045
202        volvo  21485
203        volvo  22470
204        volvo  22625

[205 rows x 2 columns]
```

As you can see, the variable `subset` now contains a reduced matrix/table from the original one, composed from the "make" and "price" columns.

Sometimes it comes in handy to retrieve information from a specific row instead of a column. For this, Pandas also provides with a method: `loc`.

_Actually, the `loc` method is used for both column and row accessing, but the complete analysis of all its variants falls beyond the scope of this tutorial._

```python
print(df.loc[0])
```

```
symboling                      3
normalized-losses              ?
make                 alfa-romero
fuel-type                    gas
aspiration                   std
num-of-doors                 two
body-style           convertible
drive-wheels                 rwd
engine-location            front
wheel-base                  88.6
length                     168.8
width                       64.1
height                      48.8
curb-weight                 2548
engine-type                 dohc
num-of-cylinders            four
engine-size                  130
fuel-system                 mpfi
bore                        3.47
stroke                      2.68
compression-ratio            9.0
horsepower                   111
peak-rpm                    5000
city-mpg                      21
highway-mpg                   27
price                      13495
Name: 0, dtype: object
```

As you can see, this returns the complete information of the first (non-header) row.

# 3. Saving files

Since we've now read our file, inspected it and even added a header row to its dataframe, the next step is to save the changes locally. This part is really interesting -at least for me-, since you can convert the dataframe to supported format. Let's say that we wanted to convert the current dataframe (whose origin was a CSV file) to a JSON format. Then we could use the following statement:

```python
df.to_json("output.json")
```

This will generate a file called "output.json" in the directory where the script is running. This file will contain all the data in the dataframe and can be read in further occasions via the syntax explained in the first section of this tutorial, but this time using `read_json("output.json")` to read the file.

# Summary

In this tutorial you've learned how to read, visualize, save and even modify tiny sections of a file using the Pandas module. In the next chapters of the tutorial series, you will learn how to identify and modify data types in a dataframe, replace specific values and much more!
